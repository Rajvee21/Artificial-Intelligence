{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CSC 215 Artificial Intelligence (Spring 2023)\n",
    "\n",
    "#### Dr. Haiquan Chen, Dept of Computer Scicence\n",
    "\n",
    "#### California State University, Sacramento\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wj0Kab0tIvSp"
   },
   "source": [
    "# CSC 215  Lab 15:  GPU and Transfer Learning\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KW50tIoYU2eM"
   },
   "source": [
    "### Please run this lab in Google Colab.  \n",
    "\n",
    "**You may want to (1) mount your google drive so colab can access your files on google drive and (2) use Google GPU  for model training.** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3oDs4JQ6ox3s"
   },
   "source": [
    "\n",
    "## 1. Mount Google drive to colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 123
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 33939,
     "status": "ok",
     "timestamp": 1565626992292,
     "user": {
      "displayName": "Victor Chen",
      "photoUrl": "",
      "userId": "00864070257040861597"
     },
     "user_tz": 420
    },
    "id": "O4Bif01-U2eI",
    "outputId": "67321742-a0e6-434c-db34-d7201be69fd5"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mr7sY7vqVEvj"
   },
   "source": [
    "## Helpful Functions for Tensorflow (Little Gems)\n",
    "\n",
    "The following functions will be used with TensorFlow to help preprocess the data.  They allow you to build the feature vector for a neural network. \n",
    "\n",
    "* Predictors/Inputs \n",
    "    * Fill any missing inputs with the median for that column.  Use **missing_median**.\n",
    "    * Encode textual/categorical values with **encode_text_dummy**.\n",
    "    * Encode numeric values with **encode_numeric_zscore**.\n",
    "* Output\n",
    "    * Discard rows with missing outputs.\n",
    "    * Encode textual/categorical values with **encode_text_index**.\n",
    "    * Do not encode output numeric values.\n",
    "* Produce final feature vectors (x) and expected output (y) with **to_xy**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f28h8NtXU2ds"
   },
   "outputs": [],
   "source": [
    "from collections.abc import Sequence\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "\n",
    "# Encode text values to dummy variables(i.e. [1,0,0],[0,1,0],[0,0,1] for red,green,blue)\n",
    "def encode_text_dummy(df, name):\n",
    "    dummies = pd.get_dummies(df[name])\n",
    "    for x in dummies.columns:\n",
    "        dummy_name = \"{}-{}\".format(name, x)\n",
    "        df[dummy_name] = dummies[x]\n",
    "    df.drop(name, axis=1, inplace=True)\n",
    "\n",
    "\n",
    "# Encode text values to indexes(i.e. [1],[2],[3] for red,green,blue).\n",
    "def encode_text_index(df, name):\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    df[name] = le.fit_transform(df[name])\n",
    "    return le.classes_\n",
    "\n",
    "\n",
    "# Encode a numeric column as zscores\n",
    "def encode_numeric_zscore(df, name, mean=None, sd=None):\n",
    "    if mean is None:\n",
    "        mean = df[name].mean()\n",
    "\n",
    "    if sd is None:\n",
    "        sd = df[name].std()\n",
    "\n",
    "    df[name] = (df[name] - mean) / sd\n",
    "\n",
    "\n",
    "# Convert all missing values in the specified column to the median\n",
    "def missing_median(df, name):\n",
    "    med = df[name].median()\n",
    "    df[name] = df[name].fillna(med)\n",
    "\n",
    "\n",
    "# Convert all missing values in the specified column to the default\n",
    "def missing_default(df, name, default_value):\n",
    "    df[name] = df[name].fillna(default_value)\n",
    "\n",
    "\n",
    "# Convert a Pandas dataframe to the x,y inputs that TensorFlow needs\n",
    "def to_xy(df, target):\n",
    "    result = []\n",
    "    for x in df.columns:\n",
    "        if x != target:\n",
    "            result.append(x)\n",
    "    # find out the type of the target column. \n",
    "    target_type = df[target].dtypes\n",
    "    target_type = target_type[0] if isinstance(target_type, Sequence) else target_type\n",
    "    # Encode to int for classification, float otherwise. TensorFlow likes 32 bits.\n",
    "    if target_type in (np.int64, np.int32):\n",
    "        # Classification\n",
    "        dummies = pd.get_dummies(df[target])\n",
    "        return df[result].values.astype(np.float32), dummies.values.astype(np.float32)\n",
    "    else:\n",
    "        # Regression\n",
    "        return df[result].values.astype(np.float32), df[target].values.astype(np.float32)\n",
    "\n",
    "# Nicely formatted time string\n",
    "def hms_string(sec_elapsed):\n",
    "    h = int(sec_elapsed / (60 * 60))\n",
    "    m = int((sec_elapsed % (60 * 60)) / 60)\n",
    "    s = sec_elapsed % 60\n",
    "    return \"{}:{:>02}:{:>05.2f}\".format(h, m, s)\n",
    "\n",
    "\n",
    "# Regression chart.\n",
    "def chart_regression(pred,y,sort=True):\n",
    "    t = pd.DataFrame({'pred' : pred, 'y' : y.flatten()})\n",
    "    if sort:\n",
    "        t.sort_values(by=['y'],inplace=True)\n",
    "    a = plt.plot(t['y'].tolist(),label='expected')\n",
    "    b = plt.plot(t['pred'].tolist(),label='prediction')\n",
    "    plt.ylabel('output')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Remove all rows where the specified column is +/- sd standard deviations\n",
    "def remove_outliers(df, name, sd):\n",
    "    drop_rows = df.index[(np.abs(df[name] - df[name].mean()) >= (sd * df[name].std()))]\n",
    "    df.drop(drop_rows, axis=0, inplace=True)\n",
    "\n",
    "\n",
    "# Encode a column to a range between normalized_low and normalized_high.\n",
    "def encode_numeric_range(df, name, normalized_low=-1, normalized_high=1,\n",
    "                         data_low=None, data_high=None):\n",
    "    if data_low is None:\n",
    "        data_low = min(df[name])\n",
    "        data_high = max(df[name])\n",
    "\n",
    "    df[name] = ((df[name] - data_low) / (data_high - data_low)) \\\n",
    "               * (normalized_high - normalized_low) + normalized_low\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qU8FIYWRVXM1"
   },
   "source": [
    "## 2. Switch and Verify GPU\n",
    "\n",
    "### To enable GPU backend for your notebook. Runtime->Change runtime type->Hardware Accelerator->GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 357,
     "status": "ok",
     "timestamp": 1565632604106,
     "user": {
      "displayName": "Victor Chen",
      "photoUrl": "",
      "userId": "00864070257040861597"
     },
     "user_tz": 420
    },
    "id": "1s9pBa09U_zJ",
    "outputId": "bee261c8-3211-4070-ff31-e3a8f6f065a7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/device:GPU:0'"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wLIW7qseIvSv"
   },
   "source": [
    "## 3. Example:  Using GPU for classification on the fashion_mnist dataset \n",
    "\n",
    "https://github.com/zalandoresearch/fashion-mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q3xXMK54AmfT"
   },
   "source": [
    "### 3.1 Load datasets\n",
    "\n",
    "\n",
    "Dataset of 60,000 28x28 grayscale images of 10 fashion categories, along with a test set of 10,000 images. This dataset can be used as a drop-in replacement for MNIST. The class labels are:\n",
    "\n",
    "\n",
    "Label\tDescription\n",
    "0\tT-shirt/top\n",
    "1\tTrouser\n",
    "2\tPullover\n",
    "3\tDress\n",
    "4\tCoat\n",
    "5\tSandal\n",
    "6\tShirt\n",
    "7\tSneaker\n",
    "8\tBag\n",
    "9\tAnkle boot\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "https://keras.io/datasets/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1084,
     "status": "ok",
     "timestamp": 1580862073941,
     "user": {
      "displayName": "Victor Chen",
      "photoUrl": "",
      "userId": "00864070257040861597"
     },
     "user_tz": 480
    },
    "id": "L2f6tlbsIvSw",
    "outputId": "a17cf9f6-94a3-4280-ad91-c17bfca21466"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
      "32768/29515 [=================================] - 0s 1us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
      "26427392/26421880 [==============================] - 2s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
      "8192/5148 [===============================================] - 0s 0s/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
      "4423680/4422102 [==============================] - 0s 0us/step\n",
      "Shape of x_train: (60000, 28, 28)\n",
      "Shape of y_train: (60000,)\n",
      "\n",
      "Shape of x_test: (10000, 28, 28)\n",
      "Shape of y_test: (10000,)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "print(\"Shape of x_train: {}\".format(x_train.shape))\n",
    "print(\"Shape of y_train: {}\".format(y_train.shape))\n",
    "print()\n",
    "print(\"Shape of x_test: {}\".format(x_test.shape))\n",
    "print(\"Shape of y_test: {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 494,
     "status": "ok",
     "timestamp": 1580862082031,
     "user": {
      "displayName": "Victor Chen",
      "photoUrl": "",
      "userId": "00864070257040861597"
     },
     "user_tz": 480
    },
    "id": "iPcsHNDsIvS5",
    "outputId": "f494873c-485c-4f4f-d1ea-7183cedf1cf9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 0, 0, ..., 3, 0, 5], dtype=uint8)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tgi4KWqJIvS_"
   },
   "source": [
    "### 3.2 Display the Images \n",
    "\n",
    "The following code shows what the MNIST files contain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 917
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 493,
     "status": "ok",
     "timestamp": 1580861665238,
     "user": {
      "displayName": "Victor Chen",
      "photoUrl": "",
      "userId": "00864070257040861597"
     },
     "user_tz": 480
    },
    "id": "ApITQfljIvTB",
    "outputId": "c1ef299d-8e38-4642-fadf-d5a525dea114"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>144</td>\n",
       "      <td>123</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>107</td>\n",
       "      <td>156</td>\n",
       "      <td>161</td>\n",
       "      <td>109</td>\n",
       "      <td>64</td>\n",
       "      <td>23</td>\n",
       "      <td>77</td>\n",
       "      <td>130</td>\n",
       "      <td>72</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>216</td>\n",
       "      <td>163</td>\n",
       "      <td>127</td>\n",
       "      <td>121</td>\n",
       "      <td>122</td>\n",
       "      <td>146</td>\n",
       "      <td>141</td>\n",
       "      <td>88</td>\n",
       "      <td>172</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>223</td>\n",
       "      <td>223</td>\n",
       "      <td>215</td>\n",
       "      <td>213</td>\n",
       "      <td>164</td>\n",
       "      <td>127</td>\n",
       "      <td>123</td>\n",
       "      <td>196</td>\n",
       "      <td>229</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>235</td>\n",
       "      <td>227</td>\n",
       "      <td>224</td>\n",
       "      <td>222</td>\n",
       "      <td>224</td>\n",
       "      <td>221</td>\n",
       "      <td>223</td>\n",
       "      <td>245</td>\n",
       "      <td>173</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>180</td>\n",
       "      <td>212</td>\n",
       "      <td>210</td>\n",
       "      <td>211</td>\n",
       "      <td>213</td>\n",
       "      <td>223</td>\n",
       "      <td>220</td>\n",
       "      <td>243</td>\n",
       "      <td>202</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>169</td>\n",
       "      <td>227</td>\n",
       "      <td>208</td>\n",
       "      <td>218</td>\n",
       "      <td>224</td>\n",
       "      <td>212</td>\n",
       "      <td>226</td>\n",
       "      <td>197</td>\n",
       "      <td>209</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>198</td>\n",
       "      <td>221</td>\n",
       "      <td>215</td>\n",
       "      <td>213</td>\n",
       "      <td>222</td>\n",
       "      <td>220</td>\n",
       "      <td>245</td>\n",
       "      <td>119</td>\n",
       "      <td>167</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>232</td>\n",
       "      <td>213</td>\n",
       "      <td>218</td>\n",
       "      <td>223</td>\n",
       "      <td>234</td>\n",
       "      <td>217</td>\n",
       "      <td>217</td>\n",
       "      <td>209</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>222</td>\n",
       "      <td>221</td>\n",
       "      <td>216</td>\n",
       "      <td>223</td>\n",
       "      <td>229</td>\n",
       "      <td>215</td>\n",
       "      <td>218</td>\n",
       "      <td>255</td>\n",
       "      <td>77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>62</td>\n",
       "      <td>...</td>\n",
       "      <td>211</td>\n",
       "      <td>218</td>\n",
       "      <td>224</td>\n",
       "      <td>223</td>\n",
       "      <td>219</td>\n",
       "      <td>215</td>\n",
       "      <td>224</td>\n",
       "      <td>244</td>\n",
       "      <td>159</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>44</td>\n",
       "      <td>82</td>\n",
       "      <td>107</td>\n",
       "      <td>189</td>\n",
       "      <td>228</td>\n",
       "      <td>...</td>\n",
       "      <td>224</td>\n",
       "      <td>234</td>\n",
       "      <td>176</td>\n",
       "      <td>188</td>\n",
       "      <td>250</td>\n",
       "      <td>248</td>\n",
       "      <td>233</td>\n",
       "      <td>238</td>\n",
       "      <td>215</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>187</td>\n",
       "      <td>208</td>\n",
       "      <td>224</td>\n",
       "      <td>221</td>\n",
       "      <td>224</td>\n",
       "      <td>208</td>\n",
       "      <td>204</td>\n",
       "      <td>214</td>\n",
       "      <td>...</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>221</td>\n",
       "      <td>234</td>\n",
       "      <td>221</td>\n",
       "      <td>211</td>\n",
       "      <td>220</td>\n",
       "      <td>232</td>\n",
       "      <td>246</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3</td>\n",
       "      <td>202</td>\n",
       "      <td>228</td>\n",
       "      <td>224</td>\n",
       "      <td>221</td>\n",
       "      <td>211</td>\n",
       "      <td>211</td>\n",
       "      <td>214</td>\n",
       "      <td>205</td>\n",
       "      <td>205</td>\n",
       "      <td>...</td>\n",
       "      <td>188</td>\n",
       "      <td>154</td>\n",
       "      <td>191</td>\n",
       "      <td>210</td>\n",
       "      <td>204</td>\n",
       "      <td>209</td>\n",
       "      <td>222</td>\n",
       "      <td>228</td>\n",
       "      <td>225</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>98</td>\n",
       "      <td>233</td>\n",
       "      <td>198</td>\n",
       "      <td>210</td>\n",
       "      <td>222</td>\n",
       "      <td>229</td>\n",
       "      <td>229</td>\n",
       "      <td>234</td>\n",
       "      <td>249</td>\n",
       "      <td>220</td>\n",
       "      <td>...</td>\n",
       "      <td>168</td>\n",
       "      <td>219</td>\n",
       "      <td>221</td>\n",
       "      <td>215</td>\n",
       "      <td>217</td>\n",
       "      <td>223</td>\n",
       "      <td>223</td>\n",
       "      <td>224</td>\n",
       "      <td>229</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>75</td>\n",
       "      <td>204</td>\n",
       "      <td>212</td>\n",
       "      <td>204</td>\n",
       "      <td>193</td>\n",
       "      <td>205</td>\n",
       "      <td>211</td>\n",
       "      <td>225</td>\n",
       "      <td>216</td>\n",
       "      <td>185</td>\n",
       "      <td>...</td>\n",
       "      <td>239</td>\n",
       "      <td>223</td>\n",
       "      <td>218</td>\n",
       "      <td>212</td>\n",
       "      <td>209</td>\n",
       "      <td>222</td>\n",
       "      <td>220</td>\n",
       "      <td>221</td>\n",
       "      <td>230</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>48</td>\n",
       "      <td>203</td>\n",
       "      <td>183</td>\n",
       "      <td>194</td>\n",
       "      <td>213</td>\n",
       "      <td>197</td>\n",
       "      <td>185</td>\n",
       "      <td>190</td>\n",
       "      <td>194</td>\n",
       "      <td>192</td>\n",
       "      <td>...</td>\n",
       "      <td>199</td>\n",
       "      <td>206</td>\n",
       "      <td>186</td>\n",
       "      <td>181</td>\n",
       "      <td>177</td>\n",
       "      <td>172</td>\n",
       "      <td>181</td>\n",
       "      <td>205</td>\n",
       "      <td>206</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>122</td>\n",
       "      <td>219</td>\n",
       "      <td>193</td>\n",
       "      <td>179</td>\n",
       "      <td>171</td>\n",
       "      <td>183</td>\n",
       "      <td>196</td>\n",
       "      <td>204</td>\n",
       "      <td>210</td>\n",
       "      <td>...</td>\n",
       "      <td>195</td>\n",
       "      <td>191</td>\n",
       "      <td>198</td>\n",
       "      <td>192</td>\n",
       "      <td>176</td>\n",
       "      <td>156</td>\n",
       "      <td>167</td>\n",
       "      <td>177</td>\n",
       "      <td>210</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>74</td>\n",
       "      <td>189</td>\n",
       "      <td>212</td>\n",
       "      <td>191</td>\n",
       "      <td>175</td>\n",
       "      <td>172</td>\n",
       "      <td>175</td>\n",
       "      <td>181</td>\n",
       "      <td>...</td>\n",
       "      <td>210</td>\n",
       "      <td>210</td>\n",
       "      <td>211</td>\n",
       "      <td>188</td>\n",
       "      <td>188</td>\n",
       "      <td>194</td>\n",
       "      <td>192</td>\n",
       "      <td>216</td>\n",
       "      <td>170</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>66</td>\n",
       "      <td>200</td>\n",
       "      <td>222</td>\n",
       "      <td>237</td>\n",
       "      <td>239</td>\n",
       "      <td>242</td>\n",
       "      <td>...</td>\n",
       "      <td>182</td>\n",
       "      <td>182</td>\n",
       "      <td>181</td>\n",
       "      <td>176</td>\n",
       "      <td>166</td>\n",
       "      <td>168</td>\n",
       "      <td>99</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>61</td>\n",
       "      <td>44</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    0    1    2    3    4    5    6    7    8    9   ...   18   19   20   21  \\\n",
       "0    0    0    0    0    0    0    0    0    0    0  ...    0    0    0    0   \n",
       "1    0    0    0    0    0    0    0    0    0    0  ...    0    0    0    0   \n",
       "2    0    0    0    0    0    0    0    0    0    0  ...    0    0    0    0   \n",
       "3    0    0    0    0    0    0    0    0    0    0  ...    0    1    4    0   \n",
       "4    0    0    0    0    0    0    0    0    0    0  ...   54    0    0    0   \n",
       "5    0    0    0    0    0    0    0    0    0    0  ...  144  123   23    0   \n",
       "6    0    0    0    0    0    0    0    0    0    0  ...  107  156  161  109   \n",
       "7    0    0    0    0    0    0    0    0    0    0  ...  216  163  127  121   \n",
       "8    0    0    0    0    0    0    0    0    0    1  ...  223  223  215  213   \n",
       "9    0    0    0    0    0    0    0    0    0    0  ...  235  227  224  222   \n",
       "10   0    0    0    0    0    0    0    0    0    0  ...  180  212  210  211   \n",
       "11   0    0    0    0    0    0    0    0    0    1  ...  169  227  208  218   \n",
       "12   0    0    0    0    0    0    0    0    0    0  ...  198  221  215  213   \n",
       "13   0    0    0    0    0    0    0    0    0    4  ...  232  213  218  223   \n",
       "14   0    0    1    4    6    7    2    0    0    0  ...  222  221  216  223   \n",
       "15   0    3    0    0    0    0    0    0    0   62  ...  211  218  224  223   \n",
       "16   0    0    0    0   18   44   82  107  189  228  ...  224  234  176  188   \n",
       "17   0   57  187  208  224  221  224  208  204  214  ...  255  255  221  234   \n",
       "18   3  202  228  224  221  211  211  214  205  205  ...  188  154  191  210   \n",
       "19  98  233  198  210  222  229  229  234  249  220  ...  168  219  221  215   \n",
       "20  75  204  212  204  193  205  211  225  216  185  ...  239  223  218  212   \n",
       "21  48  203  183  194  213  197  185  190  194  192  ...  199  206  186  181   \n",
       "22   0  122  219  193  179  171  183  196  204  210  ...  195  191  198  192   \n",
       "23   0    0   74  189  212  191  175  172  175  181  ...  210  210  211  188   \n",
       "24   2    0    0    0   66  200  222  237  239  242  ...  182  182  181  176   \n",
       "25   0    0    0    0    0    0    0   40   61   44  ...    0    0    0    0   \n",
       "26   0    0    0    0    0    0    0    0    0    0  ...    0    0    0    0   \n",
       "27   0    0    0    0    0    0    0    0    0    0  ...    0    0    0    0   \n",
       "\n",
       "     22   23   24   25   26   27  \n",
       "0     0    0    0    0    0    0  \n",
       "1     0    0    0    0    0    0  \n",
       "2     0    0    0    0    0    0  \n",
       "3     0    0    0    1    1    0  \n",
       "4     1    3    4    0    0    3  \n",
       "5     0    0    0   12   10    0  \n",
       "6    64   23   77  130   72   15  \n",
       "7   122  146  141   88  172   66  \n",
       "8   164  127  123  196  229    0  \n",
       "9   224  221  223  245  173    0  \n",
       "10  213  223  220  243  202    0  \n",
       "11  224  212  226  197  209   52  \n",
       "12  222  220  245  119  167   56  \n",
       "13  234  217  217  209   92    0  \n",
       "14  229  215  218  255   77    0  \n",
       "15  219  215  224  244  159    0  \n",
       "16  250  248  233  238  215    0  \n",
       "17  221  211  220  232  246    0  \n",
       "18  204  209  222  228  225    0  \n",
       "19  217  223  223  224  229   29  \n",
       "20  209  222  220  221  230   67  \n",
       "21  177  172  181  205  206  115  \n",
       "22  176  156  167  177  210   92  \n",
       "23  188  194  192  216  170    0  \n",
       "24  166  168   99   58    0    0  \n",
       "25    0    0    0    0    0    0  \n",
       "26    0    0    0    0    0    0  \n",
       "27    0    0    0    0    0    0  \n",
       "\n",
       "[28 rows x 28 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Single MNIST digit\n",
    "first = x_train[0]\n",
    "\n",
    "pd.DataFrame(first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 446,
     "status": "ok",
     "timestamp": 1580861716762,
     "user": {
      "displayName": "Victor Chen",
      "photoUrl": "",
      "userId": "00864070257040861597"
     },
     "user_tz": 480
    },
    "id": "4bflwoTFIvTG",
    "outputId": "7c3bc913-d591-4f83-d648-7a67ed3bb358",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image (#0): Which is for label '9'\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# let's show it as image\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sample = 0    #  change this number to select another sample\n",
    "\n",
    "\n",
    "plt.imshow(x_train[sample], cmap='gray')\n",
    "\n",
    "print(\"Image (#{}): Which is for label '{}'\".format(sample,y_train[sample]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w6hRuUyWIvTM"
   },
   "source": [
    "### 3.3 Define CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AkHiifEqIvTS"
   },
   "outputs": [],
   "source": [
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zKh9etTEIvTW"
   },
   "source": [
    "#### Let's create x (images) first.        \n",
    "\n",
    "####  x must be 4D array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0cyX0-nKIvTY"
   },
   "source": [
    "#### You must explicitly declare the depth of the input image. For example, a full-color image with all 3 RGB channels will have a depth of 3. \n",
    "\n",
    "In other words, we need to transform our dataset from the shape (n, rows, cols) to (n, rows, cols, depth).\n",
    "\n",
    "#### Our MNIST images only have a depth of 1, but we must explicitly declare that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4HPB4gIcIvTZ"
   },
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 455,
     "status": "ok",
     "timestamp": 1580862470360,
     "user": {
      "displayName": "Victor Chen",
      "photoUrl": "",
      "userId": "00864070257040861597"
     },
     "user_tz": 480
    },
    "id": "OBb9IxIGIvTd",
    "outputId": "30c416c9-25ef-4f01-b1e3-05befbeb9f17"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1)\n",
      "(10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 475,
     "status": "ok",
     "timestamp": 1580862473125,
     "user": {
      "displayName": "Victor Chen",
      "photoUrl": "",
      "userId": "00864070257040861597"
     },
     "user_tz": 480
    },
    "id": "78vjG4QaIvTj",
    "outputId": "be378247-2333-42da-8f00-5ee9bcfc2111"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('uint8')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Jb0W2Tt2IvTp"
   },
   "outputs": [],
   "source": [
    "# convert to float32 for normalization\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eX4yc9K5IvTs"
   },
   "outputs": [],
   "source": [
    "# normalize the data values to the range [0, 1]\n",
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 843,
     "status": "ok",
     "timestamp": 1580862480602,
     "user": {
      "displayName": "Victor Chen",
      "photoUrl": "",
      "userId": "00864070257040861597"
     },
     "user_tz": 480
    },
    "id": "GfN88boqIvTv",
    "outputId": "4b1ba914-5524-4021-fa09-cfabc2ce543d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "x_test shape: (10000, 28, 28, 1)\n",
      "Training samples: 60000\n",
      "Test samples: 10000\n"
     ]
    }
   ],
   "source": [
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)\n",
    "print(\"Training samples: {}\".format(x_train.shape[0]))\n",
    "print(\"Test samples: {}\".format(x_test.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Gvj95NMvIvTy"
   },
   "source": [
    "####  Now we have x ready. Let's create y (class labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 437,
     "status": "ok",
     "timestamp": 1580861744900,
     "user": {
      "displayName": "Victor Chen",
      "photoUrl": "",
      "userId": "00864070257040861597"
     },
     "user_tz": 480
    },
    "id": "IGJvSOxOIvTz",
    "outputId": "fc7931f3-c929-42e3-d888-81f6ef9c0f93"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000,)\n",
      "[9 0 0 3 0 2 7 2 5 5]\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape)\n",
    "print(y_train[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LsP72iFvIvT5"
   },
   "source": [
    "#### For classification, TensorFlow requires y in one hot-encoded format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GTjZyI3_IvT6"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "num_classes = 10\n",
    "\n",
    "# Converts a class vector (integers) to binary class matrix.   One-hot encoding!  Use with categorical_crossentropy.\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 534,
     "status": "ok",
     "timestamp": 1580862487940,
     "user": {
      "displayName": "Victor Chen",
      "photoUrl": "",
      "userId": "00864070257040861597"
     },
     "user_tz": 480
    },
    "id": "RCFowH5HIvT-",
    "outputId": "39e641fd-fdc3-4d54-8863-d46acf826229"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59995</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59996</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59997</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59998</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59999</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60000 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0    1    2    3    4    5    6    7    8    9\n",
       "0      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0\n",
       "1      1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "2      1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "3      0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "4      1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "...    ...  ...  ...  ...  ...  ...  ...  ...  ...  ...\n",
       "59995  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0\n",
       "59996  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "59997  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "59998  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "59999  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0\n",
       "\n",
       "[60000 rows x 10 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 499,
     "status": "ok",
     "timestamp": 1580862491298,
     "user": {
      "displayName": "Victor Chen",
      "photoUrl": "",
      "userId": "00864070257040861597"
     },
     "user_tz": 480
    },
    "id": "VDCZ3VgYIvUC",
    "outputId": "19577b29-4879-4de2-9272-d1b3ac6bdd9c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0    1    2    3    4    5    6    7    8    9\n",
       "0     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0\n",
       "1     0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "2     0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "3     0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "4     0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0\n",
       "...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...\n",
       "9995  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0\n",
       "9996  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "9997  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0\n",
       "9998  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "9999  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0\n",
       "\n",
       "[10000 rows x 10 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 432,
     "status": "ok",
     "timestamp": 1580862493068,
     "user": {
      "displayName": "Victor Chen",
      "photoUrl": "",
      "userId": "00864070257040861597"
     },
     "user_tz": 480
    },
    "id": "YlwXPMSUIvUG",
    "outputId": "0e82c694-89c5-4736-bb4b-e6e6e0974631"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 10), (10000, 10))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XxXUnbZNCPC0"
   },
   "source": [
    "#### Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nRp6lyi2IvUI"
   },
   "outputs": [],
   "source": [
    "# Load modules\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U4mhsvMQIvUK"
   },
   "outputs": [],
   "source": [
    "img_rows = 28\n",
    "\n",
    "img_cols = 28\n",
    "\n",
    "input_shape = (img_rows, img_cols, 1)        # this is the shape of each sample\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), strides=(1, 1), padding='valid',\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))    #  in this case, input_shape = (img_rows, img_cols, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "G-zXMXCwIvUO"
   },
   "source": [
    "Next, we can simply add more layers to our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2gQws41fIvUO"
   },
   "outputs": [],
   "source": [
    "# Note that number of filters from previous layer become the number of channels for current layer's input image.\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=None))\n",
    "\n",
    "model.add(Conv2D(16, kernel_size=(3, 3), strides=(1, 1), padding='valid', activation='relu'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=None))\n",
    "\n",
    "model.add(Dropout(0.25)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ynzqKepkIvUQ"
   },
   "source": [
    "So far, for model parameters, we've added two Convolution layers. To complete our model architecture, let's add a fully connected layer and then the output layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EVZJvjlvIvUQ"
   },
   "outputs": [],
   "source": [
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(128, activation='relu'))\n",
    "\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dED15m1XIvUS"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# show not only log loss but also accuracy for each epoch using metrics=['accuracy']\n",
    "\n",
    "model.compile(loss=tf.keras.losses.categorical_crossentropy, optimizer=Adam(lr=0.001, decay=1e-6), metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 785
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 55043,
     "status": "ok",
     "timestamp": 1580862565701,
     "user": {
      "displayName": "Victor Chen",
      "photoUrl": "",
      "userId": "00864070257040861597"
     },
     "user_tz": 480
    },
    "id": "UpVd_EAPIvUY",
    "outputId": "e57fb620-36bf-44c8-c33b-1b202503b3bd",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "60000/60000 - 9s - loss: 0.7899 - acc: 0.7123 - val_loss: 0.4937 - val_acc: 0.8158\n",
      "Epoch 2/100\n",
      "60000/60000 - 2s - loss: 0.5230 - acc: 0.8081 - val_loss: 0.4249 - val_acc: 0.8433\n",
      "Epoch 3/100\n",
      "60000/60000 - 2s - loss: 0.4655 - acc: 0.8298 - val_loss: 0.3983 - val_acc: 0.8540\n",
      "Epoch 4/100\n",
      "60000/60000 - 2s - loss: 0.4266 - acc: 0.8431 - val_loss: 0.3630 - val_acc: 0.8677\n",
      "Epoch 5/100\n",
      "60000/60000 - 2s - loss: 0.4002 - acc: 0.8541 - val_loss: 0.3468 - val_acc: 0.8731\n",
      "Epoch 6/100\n",
      "60000/60000 - 2s - loss: 0.3843 - acc: 0.8607 - val_loss: 0.3291 - val_acc: 0.8785\n",
      "Epoch 7/100\n",
      "60000/60000 - 2s - loss: 0.3664 - acc: 0.8648 - val_loss: 0.3166 - val_acc: 0.8851\n",
      "Epoch 8/100\n",
      "60000/60000 - 2s - loss: 0.3544 - acc: 0.8703 - val_loss: 0.3163 - val_acc: 0.8837\n",
      "Epoch 9/100\n",
      "60000/60000 - 2s - loss: 0.3428 - acc: 0.8753 - val_loss: 0.3083 - val_acc: 0.8873\n",
      "Epoch 10/100\n",
      "60000/60000 - 2s - loss: 0.3385 - acc: 0.8755 - val_loss: 0.3048 - val_acc: 0.8895\n",
      "Epoch 11/100\n",
      "60000/60000 - 2s - loss: 0.3290 - acc: 0.8778 - val_loss: 0.2999 - val_acc: 0.8879\n",
      "Epoch 12/100\n",
      "60000/60000 - 2s - loss: 0.3192 - acc: 0.8824 - val_loss: 0.2859 - val_acc: 0.8943\n",
      "Epoch 13/100\n",
      "60000/60000 - 2s - loss: 0.3135 - acc: 0.8849 - val_loss: 0.2826 - val_acc: 0.8972\n",
      "Epoch 14/100\n",
      "60000/60000 - 2s - loss: 0.3094 - acc: 0.8852 - val_loss: 0.2847 - val_acc: 0.8970\n",
      "Epoch 15/100\n",
      "60000/60000 - 2s - loss: 0.3049 - acc: 0.8876 - val_loss: 0.2754 - val_acc: 0.8994\n",
      "Epoch 16/100\n",
      "60000/60000 - 2s - loss: 0.3032 - acc: 0.8893 - val_loss: 0.2720 - val_acc: 0.9006\n",
      "Epoch 17/100\n",
      "60000/60000 - 2s - loss: 0.2973 - acc: 0.8901 - val_loss: 0.2949 - val_acc: 0.8896\n",
      "Epoch 18/100\n",
      "60000/60000 - 2s - loss: 0.2923 - acc: 0.8927 - val_loss: 0.2736 - val_acc: 0.8996\n",
      "Epoch 19/100\n",
      "60000/60000 - 2s - loss: 0.2879 - acc: 0.8934 - val_loss: 0.2639 - val_acc: 0.9005\n",
      "Epoch 00019: early stopping\n",
      "Elapsed time: 0:00:54.57\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# 100% of dataset\n",
    "\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='auto', min_delta=0.001, verbose=1, patience=3)   \n",
    "# auto : minimize loss or maximize accuracy.\n",
    "\n",
    "\n",
    "model.fit(x_train, y_train,     \n",
    "          batch_size=batch_size,\n",
    "          epochs=100,\n",
    "          verbose=2,\n",
    "          validation_data=(x_test, y_test), callbacks=[es])\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "\n",
    "print(\"Elapsed time: {}\".format(hms_string(elapsed_time)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PdGX114iIvUa"
   },
   "source": [
    "#### Evaluate Metrics using Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1372,
     "status": "ok",
     "timestamp": 1580862575211,
     "user": {
      "displayName": "Victor Chen",
      "photoUrl": "",
      "userId": "00864070257040861597"
     },
     "user_tz": 480
    },
    "id": "wcXOh7OUIvUb",
    "outputId": "f3d4056d-6b6f-488e-be53-5b438e0beec3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9005\n",
      "Averaged F1: 0.9010124240523064\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.81      0.85      1000\n",
      "           1       0.99      0.97      0.98      1000\n",
      "           2       0.86      0.85      0.86      1000\n",
      "           3       0.88      0.92      0.90      1000\n",
      "           4       0.84      0.87      0.85      1000\n",
      "           5       0.98      0.98      0.98      1000\n",
      "           6       0.68      0.72      0.70      1000\n",
      "           7       0.95      0.96      0.96      1000\n",
      "           8       0.98      0.97      0.97      1000\n",
      "           9       0.97      0.97      0.97      1000\n",
      "\n",
      "    accuracy                           0.90     10000\n",
      "   macro avg       0.90      0.90      0.90     10000\n",
      "weighted avg       0.90      0.90      0.90     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "y_true = np.argmax(y_test,axis=1)\n",
    "\n",
    "pred = model.predict(x_test)\n",
    "pred = np.argmax(pred,axis=1)\n",
    "\n",
    "score = metrics.accuracy_score(y_true, pred)\n",
    "print('Accuracy: {}'.format(score))\n",
    "\n",
    "\n",
    "f1 = metrics.f1_score(y_true, pred, average='weighted')\n",
    "print('Averaged F1: {}'.format(f1))\n",
    "\n",
    "           \n",
    "print(metrics.classification_report(y_true, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oAprHh8JIvUd"
   },
   "source": [
    "## 4. Let's do transfer learning!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 301
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 72233,
     "status": "ok",
     "timestamp": 1580862904394,
     "user": {
      "displayName": "Victor Chen",
      "photoUrl": "",
      "userId": "00864070257040861597"
     },
     "user_tz": 480
    },
    "id": "AKhJckDkIvUd",
    "outputId": "ea43cd7a-9dcd-4fbf-edb8-36f2e0309211"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_train: (60000, 28, 28)\n",
      "Shape of y_train: (60000,)\n",
      "\n",
      "Shape of x_test: (10000, 28, 28)\n",
      "Shape of y_test: (10000,)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "print(\"Shape of x_train: {}\".format(x_train.shape))\n",
    "print(\"Shape of y_train: {}\".format(y_train.shape))\n",
    "print()\n",
    "print(\"Shape of x_test: {}\".format(x_test.shape))\n",
    "print(\"Shape of y_test: {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vslN_ruYIvUi"
   },
   "source": [
    "### We are going to use VGG16\n",
    "\n",
    "https://neurohive.io/en/popular-networks/vgg16/\n",
    "\n",
    "https://keras.io/applications/\n",
    "\n",
    "\n",
    "VGG16 works on color images so we need to convert grey to RGB.\n",
    "\n",
    "Examine to understand the  code in the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bppQVVjHIvUi"
   },
   "outputs": [],
   "source": [
    "new_x_train = []\n",
    "\n",
    "for image in x_train:\n",
    "  newImage = np.stack((image, image, image), axis=-1)\n",
    "  new_x_train.append(newImage)\n",
    "  \n",
    " \n",
    "\n",
    "new_x_train= np.asarray(new_x_train)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 493,
     "status": "ok",
     "timestamp": 1580862593269,
     "user": {
      "displayName": "Victor Chen",
      "photoUrl": "",
      "userId": "00864070257040861597"
     },
     "user_tz": 480
    },
    "id": "3yIYVoBhIvUl",
    "outputId": "2c3d5a2a-9ac9-41df-acac-38e409637c83"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 3)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-_b_q5kWJGtw"
   },
   "source": [
    "Now we get images with 3 channels!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xNquPzrSIvUp"
   },
   "outputs": [],
   "source": [
    "new_x_test = []\n",
    "\n",
    "for image in x_test:\n",
    "  newImage = np.stack((image, image, image), axis=-1)\n",
    "  new_x_test.append(newImage)\n",
    "    \n",
    "    \n",
    "new_x_test = np.asarray(new_x_test)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 478,
     "status": "ok",
     "timestamp": 1580862606209,
     "user": {
      "displayName": "Victor Chen",
      "photoUrl": "",
      "userId": "00864070257040861597"
     },
     "user_tz": 480
    },
    "id": "cUtd5L7XIvUq",
    "outputId": "a43ed454-6db1-4b75-a435-39f36e6ef689"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28, 3)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_x_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OKYs6GNFIvUs"
   },
   "source": [
    "### Upsampling\n",
    "\n",
    "\n",
    "#### VGG16 supports down to 32x32 images as an input.   However the fashion-mnist images are too low in terms of resolutions (28, 28) so we need to do upsampling\n",
    "\n",
    "\n",
    "We use resize(), provided by scikit-image\n",
    "https://scikit-image.org/\n",
    "\n",
    "Check the RAM bar!  :)    You need at least 12 GB RAM to use the code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Taycu3WmIvUt"
   },
   "outputs": [],
   "source": [
    "# pip install scikit-image\n",
    "\n",
    "from skimage.transform import resize\n",
    "\n",
    "\n",
    "\n",
    "new_x_train_64x64 = np.zeros((60000, 64, 64, 3))\n",
    "\n",
    "for x in range(len(new_x_train)):\n",
    "  image = resize(new_x_train[x], (64, 64))       # resize also normalizes your image\n",
    "  new_x_train_64x64[x] = image\n",
    "\n",
    "# this process may take about a few minutes ....\n",
    "\n",
    "\n",
    "\n",
    "new_x_test_64x64 = np.zeros((10000, 64, 64, 3))\n",
    "\n",
    "for x in range(len(new_x_test)):\n",
    "  image = resize(new_x_test[x], (64, 64))\n",
    "  new_x_test_64x64[x] = image\n",
    "    \n",
    "# this process may take about a few minutes ....\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 347,
     "status": "ok",
     "timestamp": 1565636427724,
     "user": {
      "displayName": "Victor Chen",
      "photoUrl": "",
      "userId": "00864070257040861597"
     },
     "user_tz": 420
    },
    "id": "FtVEDDoHIvU1",
    "outputId": "5ba29cf3-0eb8-418b-8b64-399956cefb86"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 64, 64, 3)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_x_train_64x64.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 382,
     "status": "ok",
     "timestamp": 1565636502090,
     "user": {
      "displayName": "Victor Chen",
      "photoUrl": "",
      "userId": "00864070257040861597"
     },
     "user_tz": 420
    },
    "id": "q3_pcOz5IvU9",
    "outputId": "8bf821e6-4619-4774-9af4-20cd4adf87ed"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 64, 64, 3)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_x_test_64x64.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 379,
     "status": "ok",
     "timestamp": 1565636504028,
     "user": {
      "displayName": "Victor Chen",
      "photoUrl": "",
      "userId": "00864070257040861597"
     },
     "user_tz": 420
    },
    "id": "uU2YNDgEIvU_",
    "outputId": "36646edb-fa44-4f77-8f07-897d5f89129e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 347,
     "status": "ok",
     "timestamp": 1565636505816,
     "user": {
      "displayName": "Victor Chen",
      "photoUrl": "",
      "userId": "00864070257040861597"
     },
     "user_tz": 420
    },
    "id": "K0volxYTIvVC",
    "outputId": "2b8649d3-500e-448c-e09e-5b86b9645b0f",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PAt267YIIvVE"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Convert class vectors to one hot format\n",
    "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N40XK-irIvVF"
   },
   "source": [
    "#### Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6536,
     "status": "ok",
     "timestamp": 1565636613834,
     "user": {
      "displayName": "Victor Chen",
      "photoUrl": "",
      "userId": "00864070257040861597"
     },
     "user_tz": 420
    },
    "id": "a5SyhUVdIvVG",
    "outputId": "089b042d-0b27-47c9-ab5a-438a42fe84c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58892288/58889256 [==============================] - 3s 0us/step\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "block1_conv1 (Conv2D)        (None, 64, 64, 64)        1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 64, 64, 64)        36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 32, 32, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 32, 32, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 16, 16, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 16, 16, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 16, 16, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 8, 8, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 2, 2, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "\n",
    "\n",
    "vgg_model = VGG16(weights='imagenet', include_top=False, input_shape=(64, 64, 3))   #  first hidden layer\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "\n",
    "for layer in vgg_model.layers:\n",
    "    model.add(layer)\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GL4vW2BwIvVH"
   },
   "outputs": [],
   "source": [
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9OclUjATIvVJ"
   },
   "outputs": [],
   "source": [
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 858232,
     "status": "ok",
     "timestamp": 1565641120661,
     "user": {
      "displayName": "Victor Chen",
      "photoUrl": "",
      "userId": "00864070257040861597"
     },
     "user_tz": 420
    },
    "id": "96X3-RNuIvVK",
    "outputId": "545f8482-0468-4403-c795-8d1c46b92637",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0812 20:04:28.709821 140673025324928 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0812 20:04:28.817705 140673025324928 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      " - 35s - loss: 0.5499 - acc: 0.8214 - val_loss: 0.4121 - val_acc: 0.8520\n",
      "Epoch 2/100\n",
      " - 28s - loss: 0.3570 - acc: 0.8755 - val_loss: 0.3570 - val_acc: 0.8762\n",
      "Epoch 3/100\n",
      " - 29s - loss: 0.3210 - acc: 0.8868 - val_loss: 0.3385 - val_acc: 0.8794\n",
      "Epoch 4/100\n",
      " - 29s - loss: 0.3015 - acc: 0.8927 - val_loss: 0.3269 - val_acc: 0.8827\n",
      "Epoch 5/100\n",
      " - 29s - loss: 0.2871 - acc: 0.8974 - val_loss: 0.3199 - val_acc: 0.8854\n",
      "Epoch 6/100\n",
      " - 29s - loss: 0.2773 - acc: 0.9014 - val_loss: 0.3171 - val_acc: 0.8892\n",
      "Epoch 7/100\n",
      " - 29s - loss: 0.2694 - acc: 0.9033 - val_loss: 0.3163 - val_acc: 0.8891\n",
      "Epoch 8/100\n",
      " - 29s - loss: 0.2618 - acc: 0.9063 - val_loss: 0.3063 - val_acc: 0.8912\n",
      "Epoch 9/100\n",
      " - 30s - loss: 0.2564 - acc: 0.9072 - val_loss: 0.3090 - val_acc: 0.8905\n",
      "Epoch 10/100\n",
      " - 30s - loss: 0.2505 - acc: 0.9097 - val_loss: 0.3021 - val_acc: 0.8924\n",
      "Epoch 11/100\n",
      " - 30s - loss: 0.2468 - acc: 0.9109 - val_loss: 0.2970 - val_acc: 0.8935\n",
      "Epoch 12/100\n",
      " - 30s - loss: 0.2418 - acc: 0.9126 - val_loss: 0.3068 - val_acc: 0.8932\n",
      "Epoch 13/100\n",
      " - 30s - loss: 0.2384 - acc: 0.9138 - val_loss: 0.3018 - val_acc: 0.8933\n",
      "Epoch 14/100\n",
      " - 29s - loss: 0.2361 - acc: 0.9143 - val_loss: 0.2971 - val_acc: 0.8946\n",
      "Epoch 15/100\n",
      " - 30s - loss: 0.2324 - acc: 0.9163 - val_loss: 0.2964 - val_acc: 0.8965\n",
      "Epoch 16/100\n",
      " - 30s - loss: 0.2298 - acc: 0.9170 - val_loss: 0.2972 - val_acc: 0.8946\n",
      "Epoch 17/100\n",
      " - 30s - loss: 0.2263 - acc: 0.9180 - val_loss: 0.2972 - val_acc: 0.8932\n",
      "Epoch 18/100\n",
      " - 30s - loss: 0.2240 - acc: 0.9192 - val_loss: 0.2916 - val_acc: 0.8962\n",
      "Epoch 19/100\n",
      " - 30s - loss: 0.2225 - acc: 0.9191 - val_loss: 0.2932 - val_acc: 0.8981\n",
      "Epoch 20/100\n",
      " - 30s - loss: 0.2202 - acc: 0.9199 - val_loss: 0.2962 - val_acc: 0.8982\n",
      "Epoch 21/100\n",
      " - 30s - loss: 0.2182 - acc: 0.9210 - val_loss: 0.2911 - val_acc: 0.8978\n",
      "Epoch 22/100\n",
      " - 29s - loss: 0.2162 - acc: 0.9208 - val_loss: 0.2917 - val_acc: 0.8969\n",
      "Epoch 23/100\n",
      " - 29s - loss: 0.2139 - acc: 0.9222 - val_loss: 0.2899 - val_acc: 0.8996\n",
      "Epoch 24/100\n",
      " - 29s - loss: 0.2125 - acc: 0.9230 - val_loss: 0.2885 - val_acc: 0.9010\n",
      "Epoch 25/100\n",
      " - 29s - loss: 0.2111 - acc: 0.9235 - val_loss: 0.2953 - val_acc: 0.8963\n",
      "Epoch 26/100\n",
      " - 29s - loss: 0.2090 - acc: 0.9245 - val_loss: 0.2906 - val_acc: 0.8971\n",
      "Epoch 27/100\n",
      " - 29s - loss: 0.2072 - acc: 0.9252 - val_loss: 0.2982 - val_acc: 0.8966\n",
      "Epoch 28/100\n",
      " - 30s - loss: 0.2061 - acc: 0.9257 - val_loss: 0.2910 - val_acc: 0.8996\n",
      "Epoch 29/100\n",
      " - 30s - loss: 0.2048 - acc: 0.9249 - val_loss: 0.2908 - val_acc: 0.9003\n",
      "Epoch 00029: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff094614780>"
      ]
     },
     "execution_count": 27,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy, optimizer=Adam(lr=0.001, decay=1e-6), metrics=['accuracy'])\n",
    "\n",
    "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=5, verbose=1, mode='auto')\n",
    "\n",
    "\n",
    "model.fit(new_x_train_64x64, y_train, \n",
    "          batch_size=128,\n",
    "          epochs=10,    # change this to 100\n",
    "          verbose=2,\n",
    "          callbacks=[monitor],\n",
    "          validation_data=(new_x_test_64x64, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 327
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5684,
     "status": "ok",
     "timestamp": 1565641160218,
     "user": {
      "displayName": "Victor Chen",
      "photoUrl": "",
      "userId": "00864070257040861597"
     },
     "user_tz": 420
    },
    "id": "s1YOVlReIvVM",
    "outputId": "ff604e36-836b-4666-e0e5-2c637cc4881a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averaged F1: 0.9000713062337525\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.86      0.86      1000\n",
      "           1       0.99      0.98      0.99      1000\n",
      "           2       0.87      0.81      0.84      1000\n",
      "           3       0.89      0.89      0.89      1000\n",
      "           4       0.78      0.88      0.83      1000\n",
      "           5       0.98      0.97      0.98      1000\n",
      "           6       0.74      0.70      0.72      1000\n",
      "           7       0.94      0.98      0.96      1000\n",
      "           8       0.97      0.98      0.98      1000\n",
      "           9       0.99      0.95      0.97      1000\n",
      "\n",
      "    accuracy                           0.90     10000\n",
      "   macro avg       0.90      0.90      0.90     10000\n",
      "weighted avg       0.90      0.90      0.90     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "y_true = np.argmax(y_test,axis=1)\n",
    "\n",
    "pred = model.predict(new_x_test_64x64)\n",
    "pred = np.argmax(pred,axis=1)\n",
    "\n",
    "f1 = metrics.f1_score(y_true, pred, average='weighted')\n",
    "print('Averaged F1: {}'.format(f1))\n",
    "\n",
    "           \n",
    "print(metrics.classification_report(y_true, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SNMZtqMCIvVN"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "3oDs4JQ6ox3s"
   ],
   "machine_shape": "hm",
   "name": "CSC215 Lab14_GPU_and_transfer_learning.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8 (default, Apr 13 2021, 15:08:03) [MSC v.1916 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
