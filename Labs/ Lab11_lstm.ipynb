{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CSC 215 Artificial Intelligence (Spring 2023)\n",
    "\n",
    "#### Dr. Haiquan Chen, Dept of Computer Scicence\n",
    "\n",
    "#### California State University, Sacramento\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 11: Time-Series Forcasting using Recurrent Neural Networks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helpful Functions for Tensorflow (Little Gems)\n",
    "\n",
    "The following functions will be used with TensorFlow to help preprocess the data.  They allow you to build the feature vector for a neural network. \n",
    "\n",
    "* Predictors/Inputs \n",
    "    * Fill any missing inputs with the median for that column.  Use **missing_median**.\n",
    "    * Encode textual/categorical values with **encode_text_dummy**.\n",
    "    * Encode numeric values with **encode_numeric_zscore**.\n",
    "* Output\n",
    "    * Discard rows with missing outputs.\n",
    "    * Encode textual/categorical values with **encode_text_index**.\n",
    "    * Do not encode output numeric values.\n",
    "* Convert dataframe to numpy array to create feature vectors (x) and expected output (y) with **to_xy**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections.abc import Sequence\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "\n",
    "# Encode text values to dummy variables(i.e. [1,0,0],[0,1,0],[0,0,1] for red,green,blue)\n",
    "def encode_text_dummy(df, name):\n",
    "    dummies = pd.get_dummies(df[name])\n",
    "    for x in dummies.columns:\n",
    "        dummy_name = \"{}-{}\".format(name, x)\n",
    "        df[dummy_name] = dummies[x]\n",
    "    df.drop(name, axis=1, inplace=True)\n",
    "\n",
    "\n",
    "# Encode text values to indexes(i.e. [1],[2],[3] for red,green,blue).\n",
    "def encode_text_index(df, name):\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    df[name] = le.fit_transform(df[name])\n",
    "    return le.classes_\n",
    "\n",
    "\n",
    "# Encode a numeric column as zscores\n",
    "def encode_numeric_zscore(df, name, mean=None, sd=None):\n",
    "    if mean is None:\n",
    "        mean = df[name].mean()\n",
    "\n",
    "    if sd is None:\n",
    "        sd = df[name].std()\n",
    "\n",
    "    df[name] = (df[name] - mean) / sd\n",
    "\n",
    "\n",
    "# Convert all missing values in the specified column to the median\n",
    "def missing_median(df, name):\n",
    "    med = df[name].median()\n",
    "    df[name] = df[name].fillna(med)\n",
    "\n",
    "\n",
    "# Convert all missing values in the specified column to the default\n",
    "def missing_default(df, name, default_value):\n",
    "    df[name] = df[name].fillna(default_value)\n",
    "\n",
    "\n",
    "# Convert a Pandas dataframe to the x,y inputs that TensorFlow needs\n",
    "def to_xy(df, target):\n",
    "    result = []\n",
    "    for x in df.columns:\n",
    "        if x != target:\n",
    "            result.append(x)\n",
    "    # find out the type of the target column. \n",
    "    target_type = df[target].dtypes\n",
    "    target_type = target_type[0] if isinstance(target_type, Sequence) else target_type\n",
    "    # Encode to int for classification, float otherwise. TensorFlow likes 32 bits.\n",
    "    if target_type in (np.int64, np.int32):\n",
    "        # Classification\n",
    "        dummies = pd.get_dummies(df[target])\n",
    "        return df[result].values.astype(np.float32), dummies.values.astype(np.float32)\n",
    "    else:\n",
    "        # Regression\n",
    "        return df[result].values.astype(np.float32), df[target].values.astype(np.float32)\n",
    "\n",
    "# Nicely formatted time string\n",
    "def hms_string(sec_elapsed):\n",
    "    h = int(sec_elapsed / (60 * 60))\n",
    "    m = int((sec_elapsed % (60 * 60)) / 60)\n",
    "    s = sec_elapsed % 60\n",
    "    return \"{}:{:>02}:{:>05.2f}\".format(h, m, s)\n",
    "\n",
    "\n",
    "# Regression chart.\n",
    "def chart_regression(pred,y,sort=True):\n",
    "    t = pd.DataFrame({'pred' : pred, 'y' : y.flatten()})\n",
    "    if sort:\n",
    "        t.sort_values(by=['y'],inplace=True)\n",
    "    a = plt.plot(t['y'].tolist(),label='expected')\n",
    "    b = plt.plot(t['pred'].tolist(),label='prediction')\n",
    "    plt.ylabel('output')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Remove all rows where the specified column is +/- sd standard deviations\n",
    "def remove_outliers(df, name, sd):\n",
    "    drop_rows = df.index[(np.abs(df[name] - df[name].mean()) >= (sd * df[name].std()))]\n",
    "    df.drop(drop_rows, axis=0, inplace=True)\n",
    "\n",
    "\n",
    "# Encode a column to a range between normalized_low and normalized_high.\n",
    "def encode_numeric_range(df, name, normalized_low=-1, normalized_high=1,\n",
    "                         data_low=None, data_high=None):\n",
    "    if data_low is None:\n",
    "        data_low = min(df[name])\n",
    "        data_high = max(df[name])\n",
    "\n",
    "    df[name] = ((df[name] - data_low) / (data_high - data_low)) \\\n",
    "               * (normalized_high - normalized_low) + normalized_low\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recurrent Neural Networks (a network that can remember the past input)\n",
    "\n",
    "So far the neural networks that we’ve examined have always had forward connections.  ***these networks are called “feedforward.”***  \n",
    "\n",
    "In Recurrent neural networks, \"backward/recurrent connections\" are also allowed. A \"backward/recurrent connection\" occurs when a connection is formed between a neuron and a neuron at the same level or a neuron at a previous level.\n",
    "\n",
    "\n",
    "Most recurrent neural network architectures maintain \"state\" in the recurrent connections.  ***A recurrent neural network’s state acts as a short-term memory (context) for the neural network.***  Consequently, a recurrent neural network will not always produce the same output for a given input."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Therefore, RNN is good at predicting over sequentail data (a sequnce of vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notice that if we want to ***predict something over a sequence***,  we need to ***sequence*** our data by adding a dimension.  \n",
    "\n",
    "### x should be of 3 dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 5, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = [\n",
    "    [[32,1383],[41,2928],[39,8823],[20,1252],[15,1532]],\n",
    "    [[35,8272],[32,1383],[41,2928],[39,8823],[20,1252]],\n",
    "    [[37,2738],[35,8272],[32,1383],[41,2928],[39,8823]],\n",
    "    [[34,2845],[37,2738],[35,8272],[32,1383],[41,2928]],\n",
    "    [[32,2345],[34,2845],[37,2738],[35,8272],[32,1383]],\n",
    "]\n",
    "\n",
    "y = [\n",
    "    1,\n",
    "    -1,\n",
    "    0,\n",
    "    -1,\n",
    "    1\n",
    "]\n",
    "\n",
    "np.array(x).shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM layers in TensorFlow\n",
    "\n",
    "Long Short Term Neural Network (LSTM) are ***a type of recurrent unit***.  For TensorFlow, LSTM is provided as a layer type that can be combined with other layer types, such as dense.  \n",
    "\n",
    "https://keras.io/layers/recurrent/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropout in RNN\n",
    "\n",
    "Tensorflow privide parameters for you to use dropout in RNN.  In LSTM, you can define two types of dropout. \n",
    "\n",
    "***Regular dropout***. Applied on the inputs and/or the outputs.  They mask (or \"drop\") the vertical connections from x_t and to h_t in the picture below. \n",
    "\n",
    "***Recurrent dropout***. Recurrent dropout masks (or \"drops\") the horizontal connections between the recurrent units in the picture below.\n",
    "\n",
    "\n",
    "![LSTM Layers](images/lab11_lstm3.png \"Dropout in LSTM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Example for Classification\n",
    "\n",
    "The following code creates the LSTM network.  This is an example of RNN classification.  The following code trains on a data set (x) with a max sequence size of 6 (columns) and 6 training elements (rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding\n",
    "from tensorflow.keras.layers import LSTM\n",
    "\n",
    "# assume we have 4 classes\n",
    "num_classes = 4 \n",
    "\n",
    "x = [\n",
    "    [[0],[1],[1],[0],[0],[0]],\n",
    "    [[0],[0],[0],[2],[2],[0]],\n",
    "    [[0],[0],[0],[0],[3],[3]],\n",
    "    [[0],[2],[2],[0],[0],[0]],\n",
    "    [[0],[0],[3],[3],[0],[0]],\n",
    "    [[0],[0],[0],[0],[1],[1]]\n",
    "]\n",
    "\n",
    "\n",
    "# Tensorflow likes float32 and int32\n",
    "x = np.array(x, dtype=np.float32)\n",
    "\n",
    "y = np.array([1,2,3,2,3,0], dtype=np.int32)\n",
    "\n",
    "\n",
    "# Convert y2to dummy variables (one-hot encoding for classification problem)\n",
    "\n",
    "y_2 = tf.keras.utils.to_categorical(y, num_classes)\n",
    "y_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Like CNN,  input_shape is the shape of each sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "Train...\n",
      "Epoch 1/100\n",
      "1/1 - 0s - loss: 1.4084 - accuracy: 0.1667\n",
      "Epoch 2/100\n",
      "1/1 - 0s - loss: 1.3983 - accuracy: 0.5000\n",
      "Epoch 3/100\n",
      "1/1 - 0s - loss: 1.3939 - accuracy: 0.3333\n",
      "Epoch 4/100\n",
      "1/1 - 0s - loss: 1.3923 - accuracy: 0.3333\n",
      "Epoch 5/100\n",
      "1/1 - 0s - loss: 1.3812 - accuracy: 0.3333\n",
      "Epoch 6/100\n",
      "1/1 - 0s - loss: 1.3725 - accuracy: 0.3333\n",
      "Epoch 7/100\n",
      "1/1 - 0s - loss: 1.3711 - accuracy: 0.3333\n",
      "Epoch 8/100\n",
      "1/1 - 0s - loss: 1.3630 - accuracy: 0.3333\n",
      "Epoch 9/100\n",
      "1/1 - 0s - loss: 1.3554 - accuracy: 0.5000\n",
      "Epoch 10/100\n",
      "1/1 - 0s - loss: 1.3459 - accuracy: 0.5000\n",
      "Epoch 11/100\n",
      "1/1 - 0s - loss: 1.3359 - accuracy: 0.5000\n",
      "Epoch 12/100\n",
      "1/1 - 0s - loss: 1.3404 - accuracy: 0.5000\n",
      "Epoch 13/100\n",
      "1/1 - 0s - loss: 1.3240 - accuracy: 0.5000\n",
      "Epoch 14/100\n",
      "1/1 - 0s - loss: 1.3216 - accuracy: 0.5000\n",
      "Epoch 15/100\n",
      "1/1 - 0s - loss: 1.3191 - accuracy: 0.5000\n",
      "Epoch 16/100\n",
      "1/1 - 0s - loss: 1.3256 - accuracy: 0.3333\n",
      "Epoch 17/100\n",
      "1/1 - 0s - loss: 1.2939 - accuracy: 0.3333\n",
      "Epoch 18/100\n",
      "1/1 - 0s - loss: 1.2819 - accuracy: 0.5000\n",
      "Epoch 19/100\n",
      "1/1 - 0s - loss: 1.2730 - accuracy: 0.5000\n",
      "Epoch 20/100\n",
      "1/1 - 0s - loss: 1.2608 - accuracy: 0.5000\n",
      "Epoch 21/100\n",
      "1/1 - 0s - loss: 1.2589 - accuracy: 0.5000\n",
      "Epoch 22/100\n",
      "1/1 - 0s - loss: 1.2449 - accuracy: 0.3333\n",
      "Epoch 23/100\n",
      "1/1 - 0s - loss: 1.2364 - accuracy: 0.6667\n",
      "Epoch 24/100\n",
      "1/1 - 0s - loss: 1.2273 - accuracy: 0.5000\n",
      "Epoch 25/100\n",
      "1/1 - 0s - loss: 1.2548 - accuracy: 0.3333\n",
      "Epoch 26/100\n",
      "1/1 - 0s - loss: 1.2747 - accuracy: 0.1667\n",
      "Epoch 27/100\n",
      "1/1 - 0s - loss: 1.2008 - accuracy: 0.3333\n",
      "Epoch 28/100\n",
      "1/1 - 0s - loss: 1.2511 - accuracy: 0.6667\n",
      "Epoch 29/100\n",
      "1/1 - 0s - loss: 1.2334 - accuracy: 0.5000\n",
      "Epoch 30/100\n",
      "1/1 - 0s - loss: 1.1882 - accuracy: 0.5000\n",
      "Epoch 31/100\n",
      "1/1 - 0s - loss: 1.1755 - accuracy: 0.3333\n",
      "Epoch 32/100\n",
      "1/1 - 0s - loss: 1.2058 - accuracy: 0.3333\n",
      "Epoch 33/100\n",
      "1/1 - 0s - loss: 1.2533 - accuracy: 0.3333\n",
      "Epoch 34/100\n",
      "1/1 - 0s - loss: 1.1541 - accuracy: 0.5000\n",
      "Epoch 35/100\n",
      "1/1 - 0s - loss: 1.2038 - accuracy: 0.3333\n",
      "Epoch 36/100\n",
      "1/1 - 0s - loss: 1.2080 - accuracy: 0.3333\n",
      "Epoch 37/100\n",
      "1/1 - 0s - loss: 1.1604 - accuracy: 0.5000\n",
      "Epoch 38/100\n",
      "1/1 - 0s - loss: 1.0897 - accuracy: 0.6667\n",
      "Epoch 39/100\n",
      "1/1 - 0s - loss: 1.2494 - accuracy: 0.3333\n",
      "Epoch 40/100\n",
      "1/1 - 0s - loss: 1.1124 - accuracy: 0.6667\n",
      "Epoch 41/100\n",
      "1/1 - 0s - loss: 1.1738 - accuracy: 0.3333\n",
      "Epoch 42/100\n",
      "1/1 - 0s - loss: 1.1276 - accuracy: 0.5000\n",
      "Epoch 43/100\n",
      "1/1 - 0s - loss: 1.1433 - accuracy: 0.5000\n",
      "Epoch 44/100\n",
      "1/1 - 0s - loss: 1.0310 - accuracy: 0.5000\n",
      "Epoch 45/100\n",
      "1/1 - 0s - loss: 1.1007 - accuracy: 0.5000\n",
      "Epoch 46/100\n",
      "1/1 - 0s - loss: 1.1885 - accuracy: 0.3333\n",
      "Epoch 47/100\n",
      "1/1 - 0s - loss: 1.0692 - accuracy: 0.5000\n",
      "Epoch 48/100\n",
      "1/1 - 0s - loss: 1.0426 - accuracy: 0.5000\n",
      "Epoch 49/100\n",
      "1/1 - 0s - loss: 1.0656 - accuracy: 0.5000\n",
      "Epoch 50/100\n",
      "1/1 - 0s - loss: 1.0568 - accuracy: 0.5000\n",
      "Epoch 51/100\n",
      "1/1 - 0s - loss: 1.1053 - accuracy: 0.5000\n",
      "Epoch 52/100\n",
      "1/1 - 0s - loss: 1.2562 - accuracy: 0.3333\n",
      "Epoch 53/100\n",
      "1/1 - 0s - loss: 0.9814 - accuracy: 0.5000\n",
      "Epoch 54/100\n",
      "1/1 - 0s - loss: 0.9602 - accuracy: 0.6667\n",
      "Epoch 55/100\n",
      "1/1 - 0s - loss: 1.0252 - accuracy: 0.5000\n",
      "Epoch 56/100\n",
      "1/1 - 0s - loss: 1.0510 - accuracy: 0.5000\n",
      "Epoch 57/100\n",
      "1/1 - 0s - loss: 1.0531 - accuracy: 0.5000\n",
      "Epoch 58/100\n",
      "1/1 - 0s - loss: 0.9598 - accuracy: 0.5000\n",
      "Epoch 59/100\n",
      "1/1 - 0s - loss: 0.9981 - accuracy: 0.6667\n",
      "Epoch 60/100\n",
      "1/1 - 0s - loss: 1.2092 - accuracy: 0.3333\n",
      "Epoch 61/100\n",
      "1/1 - 0s - loss: 1.0582 - accuracy: 0.5000\n",
      "Epoch 62/100\n",
      "1/1 - 0s - loss: 1.0382 - accuracy: 0.5000\n",
      "Epoch 63/100\n",
      "1/1 - 0s - loss: 1.0167 - accuracy: 0.6667\n",
      "Epoch 64/100\n",
      "1/1 - 0s - loss: 1.0013 - accuracy: 0.5000\n",
      "Epoch 65/100\n",
      "1/1 - 0s - loss: 0.9142 - accuracy: 0.5000\n",
      "Epoch 66/100\n",
      "1/1 - 0s - loss: 0.8699 - accuracy: 0.5000\n",
      "Epoch 67/100\n",
      "1/1 - 0s - loss: 0.8729 - accuracy: 0.5000\n",
      "Epoch 68/100\n",
      "1/1 - 0s - loss: 0.9390 - accuracy: 0.5000\n",
      "Epoch 69/100\n",
      "1/1 - 0s - loss: 1.0679 - accuracy: 0.5000\n",
      "Epoch 70/100\n",
      "1/1 - 0s - loss: 0.9788 - accuracy: 0.5000\n",
      "Epoch 71/100\n",
      "1/1 - 0s - loss: 0.8879 - accuracy: 0.5000\n",
      "Epoch 72/100\n",
      "1/1 - 0s - loss: 0.7718 - accuracy: 0.6667\n",
      "Epoch 73/100\n",
      "1/1 - 0s - loss: 0.8285 - accuracy: 0.5000\n",
      "Epoch 74/100\n",
      "1/1 - 0s - loss: 0.8882 - accuracy: 0.5000\n",
      "Epoch 75/100\n",
      "1/1 - 0s - loss: 1.1166 - accuracy: 0.3333\n",
      "Epoch 76/100\n",
      "1/1 - 0s - loss: 0.7382 - accuracy: 0.6667\n",
      "Epoch 77/100\n",
      "1/1 - 0s - loss: 1.0456 - accuracy: 0.5000\n",
      "Epoch 78/100\n",
      "1/1 - 0s - loss: 1.0405 - accuracy: 0.3333\n",
      "Epoch 79/100\n",
      "1/1 - 0s - loss: 0.8496 - accuracy: 0.5000\n",
      "Epoch 80/100\n",
      "1/1 - 0s - loss: 0.9837 - accuracy: 0.5000\n",
      "Epoch 81/100\n",
      "1/1 - 0s - loss: 0.9930 - accuracy: 0.5000\n",
      "Epoch 82/100\n",
      "1/1 - 0s - loss: 0.8750 - accuracy: 0.5000\n",
      "Epoch 83/100\n",
      "1/1 - 0s - loss: 0.7366 - accuracy: 0.5000\n",
      "Epoch 84/100\n",
      "1/1 - 0s - loss: 0.7933 - accuracy: 0.5000\n",
      "Epoch 85/100\n",
      "1/1 - 0s - loss: 0.7358 - accuracy: 0.5000\n",
      "Epoch 86/100\n",
      "1/1 - 0s - loss: 0.8215 - accuracy: 0.5000\n",
      "Epoch 87/100\n",
      "1/1 - 0s - loss: 0.6459 - accuracy: 0.8333\n",
      "Epoch 88/100\n",
      "1/1 - 0s - loss: 0.8573 - accuracy: 0.5000\n",
      "Epoch 89/100\n",
      "1/1 - 0s - loss: 1.0236 - accuracy: 0.5000\n",
      "Epoch 90/100\n",
      "1/1 - 0s - loss: 0.8248 - accuracy: 0.5000\n",
      "Epoch 91/100\n",
      "1/1 - 0s - loss: 0.6741 - accuracy: 0.5000\n",
      "Epoch 92/100\n",
      "1/1 - 0s - loss: 0.9988 - accuracy: 0.5000\n",
      "Epoch 93/100\n",
      "1/1 - 0s - loss: 0.9718 - accuracy: 0.5000\n",
      "Epoch 94/100\n",
      "1/1 - 0s - loss: 0.6960 - accuracy: 0.5000\n",
      "Epoch 95/100\n",
      "1/1 - 0s - loss: 0.7068 - accuracy: 0.5000\n",
      "Epoch 96/100\n",
      "1/1 - 0s - loss: 0.6528 - accuracy: 0.6667\n",
      "Epoch 97/100\n",
      "1/1 - 0s - loss: 0.8755 - accuracy: 0.3333\n",
      "Epoch 98/100\n",
      "1/1 - 0s - loss: 0.9496 - accuracy: 0.5000\n",
      "Epoch 99/100\n",
      "1/1 - 0s - loss: 1.0973 - accuracy: 0.3333\n",
      "Epoch 100/100\n",
      "1/1 - 0s - loss: 0.7459 - accuracy: 0.5000\n",
      "Predicted classes: [2 3 3 2 3 0]\n",
      "Expected classes: [1 2 3 2 3 0]\n"
     ]
    }
   ],
   "source": [
    "# If numpy 1.20 gives you error, you may want to downgrade using pip install numpy==1.19.2\n",
    "\n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "\n",
    "# each sequence has 6 members and each member is 1-dimentinal\n",
    "\n",
    "#Like CNN,  input_shape is the shape of each sample\n",
    "\n",
    "model.add(LSTM(128, activation='relu', dropout=0.2, recurrent_dropout=0.2, input_shape=(6, 1)))\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "\n",
    "# try using different optimizers and different optimizer configs\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "print('Train...')\n",
    "model.fit(x, y_2,verbose=2, epochs=100)\n",
    "pred = model.predict(x)\n",
    "\n",
    "predict_classes = np.argmax(pred,axis=1)\n",
    "print(\"Predicted classes:\",predict_classes)\n",
    "print(\"Expected classes:\",y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's predict any ad hoc sequence using trained model\n",
    "\n",
    "For example  [[0],[0],[0],[0],[0],[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([[0],[0],[0],[0],[0],[1]])\n",
    "\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    c:\\Users\\haiquan.chen\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1462 predict_function  *\n        return step_function(self, iterator)\n    c:\\Users\\haiquan.chen\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1452 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    c:\\Users\\haiquan.chen\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    c:\\Users\\haiquan.chen\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    c:\\Users\\haiquan.chen\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    c:\\Users\\haiquan.chen\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1445 run_step  **\n        outputs = model.predict_step(data)\n    c:\\Users\\haiquan.chen\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1418 predict_step\n        return self(x, training=False)\n    c:\\Users\\haiquan.chen\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:975 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs,\n    c:\\Users\\haiquan.chen\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\input_spec.py:176 assert_input_compatibility\n        raise ValueError('Input ' + str(input_index) + ' of layer ' +\n\n    ValueError: Input 0 of layer sequential is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: [None, 1]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-21854b1e4784>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\haiquan.chen\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    128\u001b[0m       raise ValueError('{} is not supported in multi-worker mode.'.format(\n\u001b[0;32m    129\u001b[0m           method.__name__))\n\u001b[1;32m--> 130\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m   return tf_decorator.make_decorator(\n",
      "\u001b[1;32mc:\\Users\\haiquan.chen\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1597\u001b[0m           \u001b[1;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1598\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1599\u001b[1;33m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredict_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1600\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1601\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\haiquan.chen\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\haiquan.chen\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    812\u001b[0m       \u001b[1;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    813\u001b[0m       \u001b[1;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 814\u001b[1;33m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    815\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    816\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[1;32mc:\\Users\\haiquan.chen\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2826\u001b[0m     \u001b[1;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2828\u001b[1;33m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2829\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\haiquan.chen\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3208\u001b[0m           \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_signature\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3209\u001b[0m           and call_context_key in self._function_cache.missed):\n\u001b[1;32m-> 3210\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_define_function_with_shape_relaxation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3211\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3212\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\haiquan.chen\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_define_function_with_shape_relaxation\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3139\u001b[0m           expand_composites=True)\n\u001b[0;32m   3140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3141\u001b[1;33m     graph_function = self._create_graph_function(\n\u001b[0m\u001b[0;32m   3142\u001b[0m         args, kwargs, override_flat_arg_shapes=relaxed_arg_shapes)\n\u001b[0;32m   3143\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marg_relaxed\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrank_only_cache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\haiquan.chen\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3063\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3064\u001b[0m     graph_function = ConcreteFunction(\n\u001b[1;32m-> 3065\u001b[1;33m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[0;32m   3066\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3067\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\haiquan.chen\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m    984\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    985\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 986\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    987\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    988\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\haiquan.chen\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    598\u001b[0m         \u001b[1;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    599\u001b[0m         \u001b[1;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 600\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    601\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mref\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    602\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\haiquan.chen\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    971\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    972\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 973\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    974\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    975\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    c:\\Users\\haiquan.chen\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1462 predict_function  *\n        return step_function(self, iterator)\n    c:\\Users\\haiquan.chen\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1452 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    c:\\Users\\haiquan.chen\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    c:\\Users\\haiquan.chen\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    c:\\Users\\haiquan.chen\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    c:\\Users\\haiquan.chen\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1445 run_step  **\n        outputs = model.predict_step(data)\n    c:\\Users\\haiquan.chen\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1418 predict_step\n        return self(x, training=False)\n    c:\\Users\\haiquan.chen\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:975 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs,\n    c:\\Users\\haiquan.chen\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\input_spec.py:176 assert_input_compatibility\n        raise ValueError('Input ' + str(input_index) + ' of layer ' +\n\n    ValueError: Input 0 of layer sequential is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: [None, 1]\n"
     ]
    }
   ],
   "source": [
    "x = np.array(x, dtype=np.float32)  \n",
    "\n",
    "pred = model.predict(x)\n",
    "\n",
    "print(x)\n",
    "\n",
    "print(\"Prediction:\", np.argmax(pred[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why?  \n",
    "\n",
    "### Remeber x must be a 3D array!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 6, 1)\n",
      "Prediction: 0\n"
     ]
    }
   ],
   "source": [
    "x = np.array([[[0],[0],[0],[0],[0],[1]]])\n",
    "\n",
    "x = np.array(x, dtype=np.float32)  \n",
    "\n",
    "pred = model.predict(x)\n",
    "\n",
    "print(x.shape)\n",
    "\n",
    "print(\"Prediction:\", np.argmax(pred[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Example for Regression\n",
    "\n",
    "An example of RNN regression to predict sunspots.  The data files needed for this example can be found at the following location.\n",
    "\n",
    "* [Sunspot Data Files](http://www.sidc.be/silso/datafiles#total)\n",
    "\n",
    "http://www.sidc.be/silso/infosndtot\n",
    "\n",
    "The following code is used to load the sunspot file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>dec_year</th>\n",
       "      <th>sn_value</th>\n",
       "      <th>sn_error</th>\n",
       "      <th>obs_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1818</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1818.001</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1818</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1818.004</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1818</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1818.007</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1818</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1818.010</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1818</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1818.012</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1818</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1818.015</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1818</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1818.018</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1818</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1818.021</td>\n",
       "      <td>65</td>\n",
       "      <td>10.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1818</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1818.023</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1818</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1818.026</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  month  day  dec_year  sn_value  sn_error  obs_num\n",
       "0  1818      1    1  1818.001        -1      -1.0        0\n",
       "1  1818      1    2  1818.004        -1      -1.0        0\n",
       "2  1818      1    3  1818.007        -1      -1.0        0\n",
       "3  1818      1    4  1818.010        -1      -1.0        0\n",
       "4  1818      1    5  1818.012        -1      -1.0        0\n",
       "5  1818      1    6  1818.015        -1      -1.0        0\n",
       "6  1818      1    7  1818.018        -1      -1.0        0\n",
       "7  1818      1    8  1818.021        65      10.2        1\n",
       "8  1818      1    9  1818.023        -1      -1.0        0\n",
       "9  1818      1   10  1818.026        -1      -1.0        0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "path = \"./data/\"\n",
    "    \n",
    "filename = os.path.join(path,\"SN_d_tot_V2.0.csv\")   \n",
    "names = ['year', 'month', 'day', 'dec_year', 'sn_value' , 'sn_error', 'obs_num']\n",
    "df = pd.read_csv(filename, sep=';', header=None, names=names, index_col=False)\n",
    "\n",
    "# index_col=False forces pandas not to use the first column as the index\n",
    "\n",
    "df[0:10]\n",
    "\n",
    "# -1 means NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The missing values are marked by -1 \n",
    "\n",
    "df = df[(df['sn_value'] != -1) & (df['obs_num'] != 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(69922, 7)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>dec_year</th>\n",
       "      <th>sn_value</th>\n",
       "      <th>sn_error</th>\n",
       "      <th>obs_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1818</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1818.021</td>\n",
       "      <td>65</td>\n",
       "      <td>10.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1818</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>1818.034</td>\n",
       "      <td>37</td>\n",
       "      <td>7.7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1818</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>1818.045</td>\n",
       "      <td>77</td>\n",
       "      <td>11.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1818</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>1818.048</td>\n",
       "      <td>98</td>\n",
       "      <td>12.6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1818</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>1818.051</td>\n",
       "      <td>105</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1818</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>1818.067</td>\n",
       "      <td>25</td>\n",
       "      <td>6.3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1818</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>1818.075</td>\n",
       "      <td>38</td>\n",
       "      <td>7.8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1818</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>1818.078</td>\n",
       "      <td>20</td>\n",
       "      <td>5.7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1818</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1818.092</td>\n",
       "      <td>17</td>\n",
       "      <td>5.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1818</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1818.097</td>\n",
       "      <td>20</td>\n",
       "      <td>5.7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1818</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1818.100</td>\n",
       "      <td>25</td>\n",
       "      <td>6.3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1818</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1818.108</td>\n",
       "      <td>87</td>\n",
       "      <td>11.8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>1818</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>1818.119</td>\n",
       "      <td>192</td>\n",
       "      <td>17.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>1818</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>1818.122</td>\n",
       "      <td>73</td>\n",
       "      <td>10.8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1818</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>1818.125</td>\n",
       "      <td>82</td>\n",
       "      <td>11.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    year  month  day  dec_year  sn_value  sn_error  obs_num\n",
       "7   1818      1    8  1818.021        65      10.2        1\n",
       "12  1818      1   13  1818.034        37       7.7        1\n",
       "16  1818      1   17  1818.045        77      11.1        1\n",
       "17  1818      1   18  1818.048        98      12.6        1\n",
       "18  1818      1   19  1818.051       105      13.0        1\n",
       "24  1818      1   25  1818.067        25       6.3        1\n",
       "27  1818      1   28  1818.075        38       7.8        1\n",
       "28  1818      1   29  1818.078        20       5.7        1\n",
       "33  1818      2    3  1818.092        17       5.2        1\n",
       "35  1818      2    5  1818.097        20       5.7        1\n",
       "36  1818      2    6  1818.100        25       6.3        1\n",
       "39  1818      2    9  1818.108        87      11.8        1\n",
       "43  1818      2   13  1818.119       192      17.5        1\n",
       "44  1818      2   14  1818.122        73      10.8        1\n",
       "45  1818      2   15  1818.125        82      11.4        1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[0:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, we want to predict a SN value based on the $N$ preceding values.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set has 63227 records.\n",
      "Test set has 6695 records.\n"
     ]
    }
   ],
   "source": [
    "df_train = df[df['year']<2000]\n",
    "df_test = df[df['year']>=2000]\n",
    "\n",
    "spots_train = df_train['sn_value'].tolist()\n",
    "spots_test = df_test['sn_value'].tolist()\n",
    "\n",
    "print(\"Training set has {} records.\".format(len(spots_train)))\n",
    "print(\"Test set has {} records.\".format(len(spots_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequence data to create x and y in the format RNN likes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def to_sequences(seq_size, data):\n",
    "    x = []\n",
    "    y = []\n",
    "\n",
    "    for i in range(len(data)-SEQUENCE_SIZE-1):\n",
    "        #print(i)\n",
    "        window = data[i:(i+SEQUENCE_SIZE)]\n",
    "        after_window = data[i+SEQUENCE_SIZE]\n",
    "        window = [[x] for x in window]\n",
    "        #print(\"{} - {}\".format(window,after_window))\n",
    "        x.append(window)\n",
    "        y.append(after_window)\n",
    "        \n",
    "    return np.array(x),np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_train: (63216, 10, 1)\n",
      "Shape of x_test: (6684, 10, 1)\n",
      "Shape of y_train: (63216,)\n",
      "Shape of y_test: (6684,)\n"
     ]
    }
   ],
   "source": [
    "SEQUENCE_SIZE = 10\n",
    "x_train,y_train = to_sequences(SEQUENCE_SIZE,spots_train)\n",
    "x_test,y_test = to_sequences(SEQUENCE_SIZE,spots_test)\n",
    "\n",
    "print(\"Shape of x_train: {}\".format(x_train.shape))\n",
    "print(\"Shape of x_test: {}\".format(x_test.shape))\n",
    "print(\"Shape of y_train: {}\".format(y_train.shape))\n",
    "print(\"Shape of y_test: {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 65],\n",
       "        [ 37],\n",
       "        [ 77],\n",
       "        [ 98],\n",
       "        [105],\n",
       "        [ 25],\n",
       "        [ 38],\n",
       "        [ 20],\n",
       "        [ 17],\n",
       "        [ 20]],\n",
       "\n",
       "       [[ 37],\n",
       "        [ 77],\n",
       "        [ 98],\n",
       "        [105],\n",
       "        [ 25],\n",
       "        [ 38],\n",
       "        [ 20],\n",
       "        [ 17],\n",
       "        [ 20],\n",
       "        [ 25]],\n",
       "\n",
       "       [[ 77],\n",
       "        [ 98],\n",
       "        [105],\n",
       "        [ 25],\n",
       "        [ 38],\n",
       "        [ 20],\n",
       "        [ 17],\n",
       "        [ 20],\n",
       "        [ 25],\n",
       "        [ 87]],\n",
       "\n",
       "       [[ 98],\n",
       "        [105],\n",
       "        [ 25],\n",
       "        [ 38],\n",
       "        [ 20],\n",
       "        [ 17],\n",
       "        [ 20],\n",
       "        [ 25],\n",
       "        [ 87],\n",
       "        [192]],\n",
       "\n",
       "       [[105],\n",
       "        [ 25],\n",
       "        [ 38],\n",
       "        [ 20],\n",
       "        [ 17],\n",
       "        [ 20],\n",
       "        [ 25],\n",
       "        [ 87],\n",
       "        [192],\n",
       "        [ 73]]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 25,  87, 192,  73,  82])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ready to train a RNN model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "Train...\n",
      "Epoch 1/3\n",
      "1976/1976 - 8s - loss: 1348.4918 - val_loss: 433.0674\n",
      "Epoch 2/3\n",
      "1976/1976 - 8s - loss: 621.8448 - val_loss: 239.1213\n",
      "Epoch 3/3\n",
      "1976/1976 - 7s - loss: 618.8212 - val_loss: 414.4273\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x26b547c0a90>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import numpy as np\n",
    "\n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(64, dropout=0.1, recurrent_dropout=0.1, input_shape=(SEQUENCE_SIZE, 1)))\n",
    "model.add(Dense(32))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=5, verbose=1, mode='auto')\n",
    "print('Train...')\n",
    "\n",
    "model.fit(x_train,y_train,validation_data=(x_test,y_test), callbacks=[monitor],verbose=2, epochs=3)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score (RMSE): 20.35748903345908\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "pred = model.predict(x_test)\n",
    "score = np.sqrt(metrics.mean_squared_error(pred,y_test))\n",
    "print(\"Score (RMSE): {}\".format(score))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced topics when using LSTM\n",
    "\n",
    "https://keras.io/layers/recurrent/\n",
    "\n",
    "\n",
    "### Accessing the hidden state output   $\\hat{y}$  for each time slice\n",
    "\n",
    "\n",
    "It is possible to access the hidden state output $\\hat{y}$ (the cell output) for each time slice, which can be useful when developing sophisticated recurrent neural network architectures, such as the encoder-decoder model. This can be done by setting the ***return_sequences parameter to True*** when defining the LSTM layer\n",
    "\n",
    "***You must set return_sequences=True when stacking multiple LSTM layers.***\n",
    "\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(..., return_sequences=True, input_shape=(...)))\n",
    "\n",
    "model.add(LSTM(..., return_sequences=True))\n",
    "\n",
    "model.add(LSTM(..., return_sequences=True))\n",
    "\n",
    "model.add(LSTM(...))\n",
    "\n",
    "model.add(Dense(...))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing the context values (internal state) $c$ for each time slice\n",
    "\n",
    "***the return_state argument provides access to the context values (internal state) $c$ for each time slice***\n",
    "\n",
    "\n",
    "For example, we can access both the sequence of hidden state output and the internal states at the same time.\n",
    "\n",
    "This can be done as follows:\n",
    "\n",
    "LSTM(..., return_sequences=True, return_state=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References:\n",
    "\n",
    "* [Google Colab](https://colab.research.google.com/) - Free web based platform that includes Python, Juypter Notebooks, and TensorFlow with free GPU support.  No setup needed.\n",
    "* [IBM Cognitive Class Labs](https://www.datascientistworkbench.com) - Free web based platform that includes Python, Juypter Notebooks, and TensorFlow.  No setup needed.\n",
    "* [Python Anaconda](https://www.continuum.io/downloads) - Python distribution that includes many data science packages, such as Numpy, Scipy, Scikit-Learn, Pandas, and much more.\n",
    "* [TensorFlow](https://www.tensorflow.org/) - Google's mathematics package for deep learning.\n",
    "* [Kaggle](https://www.kaggle.com/) - Competitive data science.  Good source of sample data.\n",
    "* T81-558: Applications of Deep Neural Networks. Instructor: [Jeff Heaton](https://sites.wustl.edu/jeffheaton/)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "cea39816bfa6bd3c0a1f6664bad4835e3a909c2e2cb41a9f2c8a2752fd725301"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
